{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline OCR para Notas Fiscais - Demonstração Completa\n",
    "\n",
    "Este notebook demonstra o pipeline completo de extração de dados de Notas Fiscais brasileiras usando OCR.\n",
    "\n",
    "## Estrutura do Pipeline\n",
    "\n",
    "```\n",
    "Imagem NF → Pré-processamento → OCR → Extração de Campos → Dados Estruturados (JSON)\n",
    "```\n",
    "\n",
    "## Sumário\n",
    "\n",
    "1. [Configuração e Instalação](#1-configuração-e-instalação)\n",
    "2. [Base de Dados - Justificativa](#2-base-de-dados---justificativa)\n",
    "3. [Técnicas de Tratamento de Imagens](#3-técnicas-de-tratamento-de-imagens)\n",
    "4. [Modelos OCR Pré-treinados](#4-modelos-ocr-pré-treinados)\n",
    "5. [Demonstração do Pipeline Completo](#5-demonstração-do-pipeline-completo)\n",
    "6. [Uso via API](#6-uso-via-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração e Instalação\n",
    "\n",
    "### Instalação das dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação das dependências (executar apenas uma vez)\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Adiciona o diretório raiz ao path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Imports do projeto\n",
    "from src.preprocessing import ImageProcessor\n",
    "from src.ocr import OCREngine, OCRResult\n",
    "from src.extraction import NFExtractor, NFData\n",
    "from src.config import PREPROCESSING_CONFIG, OCR_CONFIG, EXTRACTION_CONFIG\n",
    "\n",
    "print(\"Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base de Dados - Justificativa\n",
    "\n",
    "### Por que não utilizamos um dataset de treinamento tradicional?\n",
    "\n",
    "Este projeto utiliza **modelos OCR pré-treinados**, o que elimina a necessidade de um dataset de treinamento próprio. Aqui está a justificativa:\n",
    "\n",
    "#### Vantagens dos Modelos Pré-treinados:\n",
    "\n",
    "1. **Treinamento Massivo**: EasyOCR e PaddleOCR foram treinados em milhões de imagens de texto em dezenas de idiomas\n",
    "\n",
    "2. **Generalização**: Os modelos já aprenderam a reconhecer fontes, tamanhos e estilos variados\n",
    "\n",
    "3. **Eficiência**: Não requer GPU para treinamento, apenas para inferência\n",
    "\n",
    "4. **Manutenção**: Atualizações dos modelos são feitas pela comunidade\n",
    "\n",
    "#### Dados Utilizados:\n",
    "\n",
    "- **Entrada**: Imagens de Notas Fiscais (DANFE - Documento Auxiliar da NF-e)\n",
    "- **Formato**: JPG, PNG, TIFF, BMP\n",
    "- **Características**: Layout padronizado pela legislação brasileira\n",
    "\n",
    "#### Campos do DANFE (Nota Fiscal Eletrônica):\n",
    "\n",
    "| Campo | Descrição |\n",
    "|-------|----------|\n",
    "| Chave de Acesso | 44 dígitos únicos |\n",
    "| CNPJ Emitente | Identificação do vendedor |\n",
    "| CNPJ Destinatário | Identificação do comprador |\n",
    "| Número NF | Número sequencial |\n",
    "| Data Emissão | Data da operação |\n",
    "| Valor Total | Valor da nota |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Técnicas de Tratamento de Imagens\n",
    "\n",
    "O pré-processamento é **fundamental** para a qualidade do OCR. Cada técnica tem uma justificativa específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o processador de imagens\n",
    "processor = ImageProcessor(PREPROCESSING_CONFIG)\n",
    "\n",
    "# Mostra configurações\n",
    "print(\"Configurações de Pré-processamento:\")\n",
    "print(json.dumps(PREPROCESSING_CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Justificativa das Técnicas\n",
    "\n",
    "| Técnica | Justificativa |\n",
    "|---------|---------------|\n",
    "| **Escala de Cinza** | Reduz complexidade, remove informação de cor irrelevante para texto |\n",
    "| **Redimensionamento** | Mínimo 300 DPI para boa leitura; muito grande = mais memória |\n",
    "| **Binarização** | Separa texto do fundo de forma clara para o OCR |\n",
    "| **Remoção de Ruído** | Artefatos de digitalização prejudicam detecção de caracteres |\n",
    "| **Correção de Inclinação** | Documentos tortos reduzem precisão do OCR significativamente |\n",
    "| **CLAHE (Contraste)** | Melhora legibilidade de documentos desbotados ou com iluminação irregular |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_preprocessing(image_path):\n",
    "    \"\"\"\n",
    "    Demonstra cada etapa do pré-processamento.\n",
    "    \"\"\"\n",
    "    # Carrega imagem\n",
    "    processor = ImageProcessor(PREPROCESSING_CONFIG)\n",
    "    \n",
    "    # Processa com retorno de etapas\n",
    "    result, steps = processor.process(image_path, return_steps=True)\n",
    "    \n",
    "    # Visualiza etapas\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    step_names = [\n",
    "        ('original', 'Original'),\n",
    "        ('resized', 'Redimensionada'),\n",
    "        ('grayscale', 'Escala de Cinza'),\n",
    "        ('denoised', 'Sem Ruído'),\n",
    "        ('contrast_enhanced', 'Contraste (CLAHE)'),\n",
    "        ('deskewed', 'Corrigida (Deskew)'),\n",
    "    ]\n",
    "    \n",
    "    for ax, (key, title) in zip(axes.flat, step_names):\n",
    "        if key in steps:\n",
    "            img = steps[key]\n",
    "            if len(img.shape) == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img, cmap='gray' if len(img.shape) == 2 else None)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Para executar com uma imagem real:\n",
    "# processed = demonstrate_preprocessing('caminho/para/nota_fiscal.jpg')\n",
    "print(\"Função demonstrate_preprocessing() pronta para uso.\")\n",
    "print(\"Uso: processed = demonstrate_preprocessing('caminho/para/imagem.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelos OCR Pré-treinados\n",
    "\n",
    "### Justificativa da Escolha dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela comparativa dos modelos\n",
    "modelos_info = \"\"\"\n",
    "╔══════════════╦═══════════════════════════════════════════════════════════════════════╗\n",
    "║ Modelo       ║ Características                                                        ║\n",
    "╠══════════════╬═══════════════════════════════════════════════════════════════════════╣\n",
    "║ EasyOCR      ║ • Baseado em Deep Learning (CRAFT + CRNN)                             ║\n",
    "║ (Principal)  ║ • Excelente suporte a português brasileiro                            ║\n",
    "║              ║ • Detecta texto em ângulos variados                                   ║\n",
    "║              ║ • Precisão: 95-98% em texto impresso                                  ║\n",
    "║              ║ • GPU acceleration disponível                                         ║\n",
    "╠══════════════╬═══════════════════════════════════════════════════════════════════════╣\n",
    "║ PaddleOCR    ║ • Estado da arte (PP-OCR v4)                                          ║\n",
    "║ (Alternativa)║ • Muito rápido e preciso                                              ║\n",
    "║              ║ • Bom para tabelas e layouts estruturados                             ║\n",
    "║              ║ • Desenvolvido pela Baidu                                             ║\n",
    "╠══════════════╬═══════════════════════════════════════════════════════════════════════╣\n",
    "║ Tesseract    ║ • Engine tradicional, mantido pelo Google                             ║\n",
    "║ (Fallback)   ║ • Confiável e bem documentado                                         ║\n",
    "║              ║ • LSTM-based desde v4.0                                               ║\n",
    "║              ║ • Útil como validação/fallback                                        ║\n",
    "╚══════════════╩═══════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "print(modelos_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o engine OCR\n",
    "print(\"Inicializando OCR Engine...\")\n",
    "print(\"(Isso pode demorar na primeira execução - download dos modelos)\\n\")\n",
    "\n",
    "try:\n",
    "    ocr_engine = OCREngine(OCR_CONFIG)\n",
    "    print(f\"Engines disponíveis: {ocr_engine.get_available_engines()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Aviso: {e}\")\n",
    "    print(\"Instale as dependências: pip install easyocr paddleocr pytesseract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Por que EasyOCR como Principal?\n",
    "\n",
    "**Arquitetura do EasyOCR:**\n",
    "\n",
    "```\n",
    "Imagem → CRAFT (Detector) → Regiões de Texto → CRNN (Reconhecedor) → Texto\n",
    "         ↓                                       ↓\n",
    "    Character Region                     CNN + BiLSTM + CTC\n",
    "    Awareness for Text                   (Sequence-to-Sequence)\n",
    "```\n",
    "\n",
    "**Vantagens específicas para Notas Fiscais:**\n",
    "\n",
    "1. Detecta texto em diferentes orientações\n",
    "2. Suporte nativo a português\n",
    "3. Bom desempenho em fontes pequenas (comum em NFs)\n",
    "4. Retorna bounding boxes precisos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demonstração do Pipeline Completo\n",
    "\n",
    "### Pipeline: Imagem → Pré-processamento → OCR → Extração → JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline completo de extração de dados de Notas Fiscais.\n",
    "    \n",
    "    Etapas:\n",
    "    1. Pré-processamento da imagem\n",
    "    2. OCR para extração de texto\n",
    "    3. Extração de campos estruturados\n",
    "    4. Validação e formatação\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.processor = ImageProcessor(PREPROCESSING_CONFIG)\n",
    "        self.ocr = OCREngine(OCR_CONFIG)\n",
    "        self.extractor = NFExtractor(EXTRACTION_CONFIG)\n",
    "        \n",
    "    def process(self, image_path, visualize=True):\n",
    "        \"\"\"\n",
    "        Processa uma imagem de Nota Fiscal.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Caminho para a imagem\n",
    "            visualize: Se deve mostrar visualizações\n",
    "            \n",
    "        Returns:\n",
    "            dict com dados extraídos\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"PIPELINE OCR - NOTA FISCAL\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. Pré-processamento\n",
    "        print(\"\\n[1/4] Pré-processamento da imagem...\")\n",
    "        processed_image, steps = self.processor.process(\n",
    "            image_path, \n",
    "            return_steps=True\n",
    "        )\n",
    "        print(f\"   ✓ Imagem processada: {processed_image.shape}\")\n",
    "        \n",
    "        if visualize:\n",
    "            self._show_preprocessing(steps)\n",
    "        \n",
    "        # 2. OCR\n",
    "        print(\"\\n[2/4] Executando OCR...\")\n",
    "        ocr_results = self.ocr.extract_text(processed_image, detail=True)\n",
    "        filtered_results = self.ocr.filter_by_confidence(ocr_results)\n",
    "        full_text = self.ocr.get_full_text(filtered_results)\n",
    "        print(f\"   ✓ {len(filtered_results)} regiões de texto detectadas\")\n",
    "        \n",
    "        if visualize:\n",
    "            self._show_ocr_results(steps['original'], ocr_results)\n",
    "        \n",
    "        # 3. Extração de campos\n",
    "        print(\"\\n[3/4] Extraindo campos da Nota Fiscal...\")\n",
    "        nf_data = self.extractor.extract(full_text)\n",
    "        print(f\"   ✓ {nf_data.campos_extraidos} campos extraídos\")\n",
    "        print(f\"   ✓ Confiança: {nf_data.confidence_score:.1%}\")\n",
    "        \n",
    "        # 4. Resultado final\n",
    "        print(\"\\n[4/4] Formatando resultado...\")\n",
    "        result = nf_data.to_dict()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DADOS EXTRAÍDOS\")\n",
    "        print(\"=\"*60)\n",
    "        self._print_result(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _show_preprocessing(self, steps):\n",
    "        \"\"\"Mostra etapas do pré-processamento.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        imgs = [\n",
    "            ('original', 'Original'),\n",
    "            ('grayscale', 'Pré-processada'),\n",
    "            ('deskewed', 'Final'),\n",
    "        ]\n",
    "        \n",
    "        for ax, (key, title) in zip(axes, imgs):\n",
    "            if key in steps:\n",
    "                img = steps[key]\n",
    "                if len(img.shape) == 3:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                ax.imshow(img, cmap='gray' if len(img.shape) == 2 else None)\n",
    "            ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle('Etapas do Pré-processamento', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _show_ocr_results(self, original_image, ocr_results):\n",
    "        \"\"\"Mostra resultados do OCR com bounding boxes.\"\"\"\n",
    "        img = original_image.copy()\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for result in ocr_results:\n",
    "            if result.bbox:\n",
    "                x1, y1, x2, y2 = result.bbox\n",
    "                color = (0, 255, 0) if result.confidence > 0.7 else (255, 165, 0)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Detecções OCR ({len(ocr_results)} regiões)')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    def _print_result(self, result):\n",
    "        \"\"\"Imprime resultado formatado.\"\"\"\n",
    "        fields = [\n",
    "            ('numero_nf', 'Número NF'),\n",
    "            ('serie', 'Série'),\n",
    "            ('chave_acesso', 'Chave de Acesso'),\n",
    "            ('data_emissao', 'Data Emissão'),\n",
    "            ('cnpj_emitente', 'CNPJ Emitente'),\n",
    "            ('razao_social_emitente', 'Razão Social Emit.'),\n",
    "            ('cnpj_destinatario', 'CNPJ Destinatário'),\n",
    "            ('nome_destinatario', 'Nome Destinatário'),\n",
    "            ('valor_total', 'Valor Total'),\n",
    "        ]\n",
    "        \n",
    "        for key, label in fields:\n",
    "            value = result.get(key, '')\n",
    "            if value:\n",
    "                if key == 'valor_total':\n",
    "                    print(f\"  {label}: R$ {value:,.2f}\")\n",
    "                else:\n",
    "                    print(f\"  {label}: {value}\")\n",
    "        \n",
    "        print(f\"\\n  Confiança: {result.get('confidence_score', 0):.1%}\")\n",
    "\n",
    "# Instancia o pipeline\n",
    "print(\"Pipeline NFPipeline criado.\")\n",
    "print(\"\\nUso:\")\n",
    "print(\"  pipeline = NFPipeline()\")\n",
    "print(\"  resultado = pipeline.process('caminho/para/nota_fiscal.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Exemplo de Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para testar com uma imagem de Nota Fiscal:\n",
    "\n",
    "# 1. Coloque uma imagem de NF na pasta samples/\n",
    "# 2. Execute:\n",
    "\n",
    "# pipeline = NFPipeline()\n",
    "# resultado = pipeline.process('../samples/nota_fiscal.jpg')\n",
    "\n",
    "# O resultado será um dicionário com todos os campos extraídos\n",
    "print(\"Para testar:\")\n",
    "print(\"1. Coloque uma imagem de NF na pasta 'samples/'\")\n",
    "print(\"2. Execute as células acima\")\n",
    "print(\"3. Use: pipeline.process('../samples/sua_nota.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Teste com Texto Simulado\n",
    "\n",
    "Para demonstrar a extração de campos sem uma imagem real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simula texto extraído de uma NF (para demonstração)\n",
    "texto_simulado = \"\"\"\n",
    "DANFE\n",
    "DOCUMENTO AUXILIAR DA NOTA FISCAL ELETRÔNICA\n",
    "\n",
    "CHAVE DE ACESSO\n",
    "3524 0612 3456 7890 1234 5600 0100 0100 0012 3456 7890\n",
    "\n",
    "NF-e N°: 123456\n",
    "SÉRIE: 1\n",
    "DATA DE EMISSÃO: 15/01/2024\n",
    "\n",
    "EMITENTE\n",
    "RAZÃO SOCIAL: EMPRESA EXEMPLO LTDA\n",
    "CNPJ: 12.345.678/0001-90\n",
    "INSCRIÇÃO ESTADUAL: 123.456.789.000\n",
    "\n",
    "DESTINATÁRIO\n",
    "NOME: CLIENTE TESTE S/A\n",
    "CNPJ: 98.765.432/0001-10\n",
    "\n",
    "VALOR TOTAL DOS PRODUTOS: R$ 1.234,56\n",
    "VALOR DO FRETE: R$ 50,00\n",
    "VALOR TOTAL DA NF: R$ 1.284,56\n",
    "\"\"\"\n",
    "\n",
    "# Testa extração\n",
    "extractor = NFExtractor(EXTRACTION_CONFIG)\n",
    "nf_data = extractor.extract(texto_simulado)\n",
    "\n",
    "print(\"RESULTADO DA EXTRAÇÃO (TEXTO SIMULADO)\")\n",
    "print(\"=\"*50)\n",
    "print(json.dumps(nf_data.to_dict(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Uso via API\n",
    "\n",
    "O backend fornece uma API REST para integração com o frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de chamada à API (após iniciar o servidor)\n",
    "\n",
    "api_example = \"\"\"\n",
    "# Iniciar o servidor:\n",
    "# python run_api.py\n",
    "\n",
    "# Endpoints disponíveis:\n",
    "# - GET  /health         → Status da API\n",
    "# - POST /ocr            → Apenas OCR (texto bruto)\n",
    "# - POST /extract        → Extração completa de dados\n",
    "\n",
    "# Exemplo com curl:\n",
    "curl -X POST \"http://localhost:8000/extract\" \\\n",
    "  -H \"accept: application/json\" \\\n",
    "  -H \"Content-Type: multipart/form-data\" \\\n",
    "  -F \"file=@nota_fiscal.jpg\"\n",
    "\n",
    "# Exemplo com Python requests:\n",
    "import requests\n",
    "\n",
    "with open('nota_fiscal.jpg', 'rb') as f:\n",
    "    response = requests.post(\n",
    "        'http://localhost:8000/extract',\n",
    "        files={'file': f}\n",
    "    )\n",
    "    \n",
    "data = response.json()\n",
    "print(data)\n",
    "\"\"\"\n",
    "\n",
    "print(api_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Documentação da API\n",
    "\n",
    "Após iniciar o servidor, acesse:\n",
    "- **Swagger UI**: http://localhost:8000/docs\n",
    "- **ReDoc**: http://localhost:8000/redoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura da resposta da API /extract\n",
    "response_example = {\n",
    "    \"success\": True,\n",
    "    \"data\": {\n",
    "        \"numero_nf\": \"123456\",\n",
    "        \"serie\": \"1\",\n",
    "        \"chave_acesso\": \"35240612345678901234560001000100001234567890\",\n",
    "        \"data_emissao\": \"15/01/2024\",\n",
    "        \"cnpj_emitente\": \"12.345.678/0001-90\",\n",
    "        \"razao_social_emitente\": \"EMPRESA EXEMPLO LTDA\",\n",
    "        \"cnpj_destinatario\": \"98.765.432/0001-10\",\n",
    "        \"nome_destinatario\": \"CLIENTE TESTE S/A\",\n",
    "        \"valor_total\": 1284.56,\n",
    "        \"confidence_score\": 0.85,\n",
    "        \"campos_extraidos\": 9\n",
    "    },\n",
    "    \"processing_info\": {\n",
    "        \"original_size\": [1200, 800],\n",
    "        \"processed_size\": [1200, 800],\n",
    "        \"ocr_engine\": \"easyocr\",\n",
    "        \"total_detections\": 45,\n",
    "        \"filtered_detections\": 38\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Exemplo de resposta da API /extract:\")\n",
    "print(json.dumps(response_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "### Escolhas Técnicas e Justificativas\n",
    "\n",
    "| Componente | Escolha | Justificativa |\n",
    "|------------|---------|---------------|\n",
    "| **Base de Dados** | Modelos pré-treinados | EasyOCR/PaddleOCR já treinados em milhões de imagens |\n",
    "| **Pré-processamento** | OpenCV | Biblioteca robusta, técnicas específicas para documentos |\n",
    "| **OCR Principal** | EasyOCR | Deep Learning, suporte a PT-BR, bounding boxes |\n",
    "| **OCR Alternativo** | PaddleOCR | Estado da arte, rápido, bom para tabelas |\n",
    "| **Extração** | Regex + Validação | Padrões conhecidos (CNPJ, datas), validação de dígitos |\n",
    "| **API** | FastAPI | Moderna, rápida, documentação automática |\n",
    "\n",
    "### Pipeline Completo\n",
    "\n",
    "```\n",
    "┌─────────────┐    ┌──────────────────┐    ┌─────────┐    ┌───────────┐    ┌──────────┐\n",
    "│   Imagem    │ → │ Pré-processamento │ → │   OCR   │ → │ Extração  │ → │   JSON   │\n",
    "│   (DANFE)   │    │  (OpenCV)        │    │(EasyOCR)│    │  (Regex)  │    │ (Dados)  │\n",
    "└─────────────┘    └──────────────────┘    └─────────┘    └───────────┘    └──────────┘\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
